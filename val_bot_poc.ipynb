{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOE/GbXcidcBxd2xnp+93iW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agalvare/reportportal/blob/master/val_bot_poc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "tpdd5nQlojAE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "GQXfPXkhu8bq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "bitLwwR1sfzc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers.legacy import SGD\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "SZZVhX8nsj02"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j0DhS0QTn0Zr"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_excel(r'/content/drive/MyDrive/validation-bot-dataset.xlsx')\n"
      ],
      "metadata": {
        "id": "2FT76mSQoaOu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "questions = ['What is your name?',\n",
        " 'What is a machine check?',\n",
        " 'What are the steps to debug a machine check?']\n",
        "responses = ['My name is amazing bot.',\n",
        " \"A machine check refers to an error or fault detected by a computer's hardware during its operation. When a computer detects a machine check error, it typically triggers an interrupt, which is a signal that halts the current operation and allows the system to gather more information about the error.\\n\\nMachine checks can be caused by a variety of factors, including hardware defects, electrical interference, and software errors. Examples of machine check errors include memory errors, CPU errors, bus errors, and input/output errors.\\n\\nWhen a machine check error occurs, the system will typically log the error and attempt to diagnose the cause of the error. Depending on the severity of the error and the system's configuration, the system may also attempt to recover from the error by retrying the operation or by shutting down the system to prevent further damage.\",\n",
        " \"Debugging a machine check can be a complex process that requires technical expertise and specialized tools. The specific steps to debug a machine check can vary depending on the type of error and the hardware and software involved. However, here are some general steps that can be followed:\\n\\nCollect system logs: When a machine check error occurs, the system will typically log information about the error, including the type of error, the location of the error, and other relevant details. Collecting these logs is the first step in diagnosing the error.\\n\\nAnalyze system configuration: Understanding the system's configuration, including the hardware and software components, can help identify potential sources of the error. Check for any recent hardware or software changes that may have caused the error.\\n\\nCheck hardware components: The error may be caused by a malfunctioning hardware component, such as the memory or the CPU. Running diagnostic tests on the hardware can help identify the faulty component.\\n\\nCheck for software issues: The error may also be caused by software issues, such as driver conflicts or operating system bugs. Analyzing software logs and updating drivers and software can help resolve these issues.\\n\\nContact technical support: If the error persists despite the above steps, contact the hardware or software vendor's technical support for further assistance.\\n\\nIt's important to note that debugging a machine check can be a complicated process that requires specialized knowledge and tools. In some cases, it may be necessary to engage with a hardware or software specialist to resolve the issue.\"]\n"
      ],
      "metadata": {
        "id": "VMdui6VQqmsN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(questions)\n",
        "sequences = tokenizer.texts_to_sequences(questions)"
      ],
      "metadata": {
        "id": "ERgqfgszwg1W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vtEPTLqwySR",
        "outputId": "03690ab1-0e0b-4824-fd64-c9776b73ba90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'what': 1,\n",
              " 'is': 2,\n",
              " 'a': 3,\n",
              " 'machine': 4,\n",
              " 'check': 5,\n",
              " 'your': 6,\n",
              " 'name': 7,\n",
              " 'are': 8,\n",
              " 'the': 9,\n",
              " 'steps': 10,\n",
              " 'to': 11,\n",
              " 'debug': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padded = pad_sequences(sequences, padding='post', maxlen=128, truncating='post') / pad_sequences(sequences, padding='post', maxlen=128, truncating='post').max()\n",
        "padded = pad_sequences(sequences, padding='post', maxlen=128, truncating='post') / 12\n",
        "padded[0]*12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmGyGGelztJ5",
        "outputId": "bd9cdbc5-03ba-4e59-8a5b-a64794dcbf4c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 6., 7., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# model.add(tf.keras.layers.Flatten(input_shape=(128,),name=\"question_input\"))\n",
        "model.add(Dense(128, input_shape=(len(padded[0]),), activation='relu',name=\"question_input\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(padded[0]), activation='softmax',name=\"response_output\"))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "  metrics=[\"accuracy\"]\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn0lAbrK0lLg",
        "outputId": "2cac8493-fb0f-4c48-e785-4c86dfeb739c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " question_input (Dense)      (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " response_output (Dense)     (None, 128)               8320      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,088\n",
            "Trainable params: 33,088\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global is_ok\n",
        "is_ok = False\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    global is_ok\n",
        "    # print(logs.get('loss'),\"<-------------\")\n",
        "    if(logs.get('accuracy')>0.95):\n",
        "      is_ok = True\n",
        "      print(f\"\\nReached {logs.get('accuracy')*100} accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()\n",
        "hist = model.fit(\n",
        "    x = np.array(padded),\n",
        "    y = np.array(padded),\n",
        "    epochs=1000, \n",
        "    batch_size=5, \n",
        "    verbose=0,\n",
        "    callbacks = [callbacks]\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgB7r_8JBTjl",
        "outputId": "be521c4d-c35d-401d-9105-fc668de62a0a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reached 100.0 accuracy so cancelling training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not is_ok:\n",
        "  exit()"
      ],
      "metadata": {
        "id": "mamibNREXENX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vkVcOUDVcoua"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is your name\"\n",
        "tokenizer2 = tf.keras.preprocessing.text.Tokenizer(num_words=5000)\n",
        "tokenizer2.fit_on_texts(questions)\n",
        "sequences = tokenizer2.texts_to_sequences([query])\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJHLN7nActeI",
        "outputId": "61fa4d80-e4d4-4418-9ff8-af2a4086c4e1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 6, 7]]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifications = model.predict(np.array(padded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtbdrOaVEAtY",
        "outputId": "f3664cc2-5b9e-4d42-db37-7277f42b2a99"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 396ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ERROR_THESHOLD = 0.25\n",
        "results = [[i, r] for i, r in enumerate(res) if r > ERROR_THESHOLD]\n",
        "results.sort(key=lambda x: x[1], reverse=True)"
      ],
      "metadata": {
        "id": "zujc3WUJbUrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifications[1]*12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkH1fJQuN6Tk",
        "outputId": "d5931e8e-ff77-4433-c793-7fb32e51976d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.9937795e-01, 1.9774200e+00, 1.6641258e+00, 4.4887629e+00,\n",
              "       3.0294728e+00, 3.3146942e-01, 8.1736416e-02, 1.9359237e-01,\n",
              "       3.4042735e-02, 1.0332225e-14, 4.1047047e-15, 1.5303491e-13,\n",
              "       2.5668638e-13, 1.8385136e-14, 3.8389898e-14, 2.4005829e-14,\n",
              "       4.8543759e-13, 1.6014650e-14, 4.0637625e-14, 9.7175643e-15,\n",
              "       4.3871919e-14, 3.2442056e-14, 2.0797674e-14, 1.8326110e-14,\n",
              "       3.4031294e-14, 1.3031800e-13, 1.3216624e-15, 1.9363179e-13,\n",
              "       2.1207306e-14, 2.7708044e-12, 8.9802569e-14, 1.4138379e-14,\n",
              "       6.3501049e-13, 1.0602535e-14, 6.6699589e-14, 1.1056191e-13,\n",
              "       1.9456167e-14, 5.8844558e-14, 5.1984445e-14, 1.2901710e-13,\n",
              "       3.5408669e-15, 2.7564837e-15, 2.7643930e-14, 1.6974373e-14,\n",
              "       2.1523624e-13, 2.2904264e-13, 7.1071621e-15, 9.4348818e-14,\n",
              "       9.5272424e-16, 8.0233587e-15, 4.8140518e-14, 6.0429466e-13,\n",
              "       3.5181395e-15, 8.9142772e-15, 2.6809467e-14, 1.1539491e-15,\n",
              "       6.8682717e-14, 1.3852335e-14, 4.1205703e-13, 4.2416655e-14,\n",
              "       1.3754088e-13, 8.2418000e-14, 4.8736954e-15, 1.0714510e-14,\n",
              "       4.3150908e-14, 6.9611421e-15, 5.7435585e-15, 6.4631799e-14,\n",
              "       2.7478825e-13, 5.5598442e-15, 7.3179330e-14, 4.2134438e-14,\n",
              "       7.0924567e-15, 2.5841295e-14, 1.2618670e-13, 2.0080578e-15,\n",
              "       4.4872926e-14, 5.8833528e-15, 5.3570606e-14, 2.3623647e-14,\n",
              "       2.4080637e-13, 6.8519422e-14, 5.5639423e-14, 6.0863646e-15,\n",
              "       3.5531409e-14, 6.9877741e-15, 1.3430696e-15, 3.9365085e-15,\n",
              "       2.2561974e-14, 1.7217363e-14, 2.3946440e-13, 3.4542163e-14,\n",
              "       2.2023263e-15, 8.5444050e-15, 4.6552897e-14, 1.1625212e-14,\n",
              "       4.5819426e-15, 1.4108854e-14, 2.2137477e-15, 1.5676168e-14,\n",
              "       3.4879661e-15, 4.6800416e-13, 7.2503921e-12, 2.3764438e-13,\n",
              "       1.6623279e-14, 1.5061319e-13, 4.1368852e-14, 2.0372938e-14,\n",
              "       1.0468010e-13, 1.7908185e-13, 1.4111061e-14, 6.5724937e-13,\n",
              "       3.4913624e-14, 5.5354047e-14, 1.4723372e-13, 6.8808761e-13,\n",
              "       3.8434296e-14, 4.4021227e-13, 4.9252095e-13, 3.7338600e-13,\n",
              "       5.3245853e-14, 1.1315143e-13, 3.5505377e-15, 7.3505140e-14,\n",
              "       5.9713709e-13, 1.9892499e-14, 9.6111053e-13, 1.1847791e-13],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_words = []\n",
        "for i in range(len(classifications)):\n",
        "  predicted_words.append(tokenizer.index_word[np.argmax(classifications[i])])\n",
        "print(predicted_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Bs1N-54R59n",
        "outputId": "d0030cfb-a854-42e6-b87f-79c149f5df45"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'a', 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(rf'100chatbot_model.h5', hist)\n",
        "# print(\"Done\")"
      ],
      "metadata": {
        "id": "h3oHxoKZ4iNL"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}