{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agalvare/reportportal/blob/master/FineTuneGODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/GODEL\n",
        "!rm -rf /content/sample_data"
      ],
      "metadata": {
        "id": "bWB1ZmcB3SYf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qyc4yKIFnFYC"
      },
      "outputs": [],
      "source": [
        "requirements = \"\"\"\n",
        "absl-py\n",
        "accelerate\n",
        "datasets\n",
        "filelock\n",
        "jsonlines\n",
        "nltk\n",
        "numpy\n",
        "python-dotenv\n",
        "rouge_score\n",
        "six\n",
        "torch\n",
        "tqdm\n",
        "transformers\n",
        "wandb\n",
        "fire\n",
        "flask\n",
        "flask-Cors\n",
        "chardet\n",
        "nltk\n",
        "beautifulsoup4\n",
        "zstandard\n",
        "flashtext\n",
        "dotmap\n",
        "nodejs\n",
        "accelerate\n",
        "\"\"\"\n",
        "text_file = open(\"requirements.txt\", \"w\")\n",
        "n = text_file.write(requirements)\n",
        "text_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -r /content/requirements.txt"
      ],
      "metadata": {
        "id": "ZPlf6_kz4oV6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf GODEL\n",
        "!git clone https://github.com/microsoft/GODEL.git\n",
        "%cd GODEL/GODEL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xs_MHLL4vBV",
        "outputId": "036cc00a-85c6-45a9-9197-d39ef6760146"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GODEL'...\n",
            "remote: Enumerating objects: 263, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 263 (delta 53), reused 46 (delta 46), pack-reused 195\u001b[K\n",
            "Receiving objects: 100% (263/263), 51.03 MiB | 23.35 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n",
            "/content/GODEL/GODEL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eQKVqt5ahcQS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "try:\n",
        "  os.mkdir(\"./data\")\n",
        "except FileExistsError:\n",
        "  print(\"File already exist!\")\n",
        "os.environ['TRAIN_SCRIPT_PATH'] = './train.py'\n",
        "os.environ['MODEL_PATH'] = './GODEL-Base'\n",
        "os.environ['INPUT_DIR'] = './data/data.json'\n",
        "os.environ['OUTPUT_DIR'] = './finetuneoutput'\n",
        "os.environ['EXP_NAME'] = 'learn_tunning'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fSS5t2jRfKm",
        "outputId": "abd31b20-79cf-4383-dc85-bd0450416885"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GODEL/GODEL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5NZF8WHs_Jyn"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "val =[  {\n",
        "    \"Context\": \"Please remind me of calling to Jessie at 2PM.\",\n",
        "    \"Knowledge\": \"reminder_contact_name is Jessie, reminder_time is 2PM\",\n",
        "    \"Response\": \"Sure, set the reminder: call to Jesse at 2PM\"\n",
        "  }]\n",
        "import pathlib\n",
        "data_path = pathlib.Path(\"data\", \"data.json\")\n",
        "if not data_path.parent.exists():\n",
        "  data_path.parent.mkdir()\n",
        "with open(data_path, \"w\") as data_fileobj:\n",
        "  for record in val:\n",
        "    # http://ndjson.org/\n",
        "    data_fileobj.write(json.dumps(val) + \"\\r\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgU6OSKVjYH4",
        "outputId": "70e7fc87-2a48-4a93-9467-6f58bed07d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-14 14:15:06--  https://bapengstorage.blob.core.windows.net/fileshare/godel_base.tar.gz\n",
            "Resolving bapengstorage.blob.core.windows.net (bapengstorage.blob.core.windows.net)... 20.150.87.36\n",
            "Connecting to bapengstorage.blob.core.windows.net (bapengstorage.blob.core.windows.net)|20.150.87.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824827060 (787M) [application/gzip]\n",
            "Saving to: ‘godel_base.tar.gz’\n",
            "\n",
            "godel_base.tar.gz   100%[===================>] 786.62M  43.9MB/s    in 22s     \n",
            "\n",
            "2023-02-14 14:15:29 (35.5 MB/s) - ‘godel_base.tar.gz’ saved [824827060/824827060]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -nc https://bapengstorage.blob.core.windows.net/fileshare/godel_base.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe2Um26Ukonj",
        "outputId": "a57c3e6c-131c-4f71-d405-370733d72700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GODEL-Base/\n",
            "GODEL-Base/tokenizer.json\n",
            "GODEL-Base/pytorch_model.bin\n",
            "GODEL-Base/config.json\n",
            "GODEL-Base/special_tokens_map.json\n",
            "GODEL-Base/tokenizer_config.json\n",
            "GODEL-Base/training_args.bin\n"
          ]
        }
      ],
      "source": [
        "!tar -zxvf godel_base.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EmGGNFaSlEWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa84ebf4-bdf9-412b-84f2-641d79e7614b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-14 14:18:31.013750: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-14 14:18:31.966131: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-14 14:18:31.966250: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-14 14:18:31.966271: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "WARNING:datasets.builder:Using custom data configuration default-57bed1cb1d8906fd\n",
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-57bed1cb1d8906fd/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n",
            "Downloading data files: 100% 3/3 [00:00<00:00, 13677.08it/s]\n",
            "Extracting data files: 100% 3/3 [00:00<00:00, 2282.41it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-57bed1cb1d8906fd/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 472.21it/s]\n",
            "loading configuration file ./GODEL-Base/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"./GODEL-Base\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 3072,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32102\n",
            "}\n",
            "\n",
            "loading file spiece.model\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading weights file ./GODEL-Base/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at ./GODEL-Base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Generation config file not found, using a generation config created from the model config.\n",
            "Assigning [PAD] to the pad_token key of the tokenizer\n",
            "WARNING:datasets.arrow_dataset:num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n",
            "Processing dataset:   0% 0/1 [00:00<?, ?ba/s]/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Processing dataset: 100% 1/1 [00:00<00:00, 17.02ba/s]\n",
            "WARNING:datasets.arrow_dataset:num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n",
            "Processing dataset: 100% 1/1 [00:00<00:00, 363.52ba/s]\n",
            "WARNING:datasets.arrow_dataset:num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n",
            "Processing dataset: 100% 1/1 [00:00<00:00, 375.03ba/s]\n",
            "INFO:__main__:Sample 0 of the training set: {'input_ids': [863, 5607, 140, 13, 3874, 12, 1022, 7, 2452, 44, 204, 6218, 5, 32101, 9561, 834, 27608, 834, 4350, 19, 1022, 7, 2452, 6, 9561, 834, 715, 19, 204, 6218, 3, 15425, 1, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [10625, 6, 356, 8, 9561, 10, 580, 12, 446, 6119, 44, 204, 6218, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "INFO:__main__:***** Running training *****\n",
            "INFO:__main__:  Num examples = 1\n",
            "INFO:__main__:  Num Epochs = 50\n",
            "INFO:__main__:  Instantaneous batch size per device = 16\n",
            "INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "INFO:__main__:  Gradient Accumulation steps = 1\n",
            "INFO:__main__:  Total optimization steps = 50\n",
            "  0% 0/50 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "INFO:__main__:  EVALERR:  0.007631958961486817\n",
            "500it [00:03, 145.40it/s] ./train.py:558: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric_rouge = load_metric(\"./utils/rouge_metric.py\")\n",
            "\n",
            "Downloading extra modules: 4.07kB [00:00, 3.65MB/s]       \n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 58.8235, 'rouge2': 26.6667, 'rougeL': 58.8235, 'rougeLsum': 58.8235}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3333333333333333, 0.125, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.125, 'translation_length': 9, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-1\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-1\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 58.8235, 'rouge2': 26.6667, 'rougeL': 58.8235, 'rougeLsum': 58.8235}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3333333333333333, 0.125, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.125, 'translation_length': 9, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-1\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-1\n",
            "INFO:__main__:  EVALERR:  0.006487525939941406\n",
            "1000it [00:05, 199.59it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 58.8235, 'rouge2': 26.6667, 'rougeL': 58.8235, 'rougeLsum': 58.8235}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3333333333333333, 0.125, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.125, 'translation_length': 9, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-2\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-2\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 58.8235, 'rouge2': 26.6667, 'rougeL': 58.8235, 'rougeLsum': 58.8235}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3333333333333333, 0.125, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.125, 'translation_length': 9, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-2\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-2\n",
            "INFO:__main__:  EVALERR:  0.005380050659179687\n",
            "1500it [00:06, 243.80it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 58.8235, 'rouge2': 26.6667, 'rougeL': 58.8235, 'rougeLsum': 58.8235}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3333333333333333, 0.125, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.125, 'translation_length': 9, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-3\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-3\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 58.8235, 'rouge2': 26.6667, 'rougeL': 58.8235, 'rougeLsum': 58.8235}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3333333333333333, 0.125, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.125, 'translation_length': 9, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-3\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-3\n",
            "INFO:__main__:  EVALERR:  0.005319962024688721\n",
            "2000it [00:08, 273.74it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 55.5556, 'rouge2': 25.0, 'rougeL': 55.5556, 'rougeLsum': 55.5556}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3, 0.1111111111111111, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.25, 'translation_length': 10, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-4\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-4\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 55.5556, 'rouge2': 25.0, 'rougeL': 55.5556, 'rougeLsum': 55.5556}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3, 0.1111111111111111, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.25, 'translation_length': 10, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-4\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-4\n",
            "INFO:__main__:  EVALERR:  0.005240093231201172\n",
            "2500it [00:09, 285.31it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 55.5556, 'rouge2': 25.0, 'rougeL': 55.5556, 'rougeLsum': 55.5556}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3, 0.1111111111111111, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.25, 'translation_length': 10, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-5\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-5\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 55.5556, 'rouge2': 25.0, 'rougeL': 55.5556, 'rougeLsum': 55.5556}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3, 0.1111111111111111, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.25, 'translation_length': 10, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-5\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-5\n",
            "INFO:__main__:  EVALERR:  0.004811850547790528\n",
            "3000it [00:11, 268.86it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 55.5556, 'rouge2': 25.0, 'rougeL': 55.5556, 'rougeLsum': 55.5556}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3, 0.1111111111111111, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.25, 'translation_length': 10, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-6\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-6\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 55.5556, 'rouge2': 25.0, 'rougeL': 55.5556, 'rougeLsum': 55.5556}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3, 0.1111111111111111, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.25, 'translation_length': 10, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-6\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-6\n",
            "INFO:__main__:  EVALERR:  0.003930127382278443\n",
            "3500it [00:14, 259.48it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-7\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-7\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-7\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-7\n",
            "INFO:__main__:  EVALERR:  0.0035647718906402586\n",
            "4000it [00:15, 278.85it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-8\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-8\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-8\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-8\n",
            "INFO:__main__:  EVALERR:  0.003398355007171631\n",
            "4500it [00:17, 294.67it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-9\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-9\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-9\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-9\n",
            "INFO:__main__:  EVALERR:  0.0032128050327301025\n",
            "5000it [00:18, 306.77it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-10\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-10\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-10\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-10\n",
            "INFO:__main__:  EVALERR:  0.0025759692192077635\n",
            "5500it [00:20, 308.38it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-11\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-11\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-11\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-11\n",
            "INFO:__main__:  EVALERR:  0.0022881014347076417\n",
            "6000it [00:21, 316.04it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-12\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-12\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-12\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-12\n",
            "INFO:__main__:  EVALERR:  0.002332470178604126\n",
            "6500it [00:23, 321.34it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-13\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-13\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-13\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-13\n",
            "INFO:__main__:  EVALERR:  0.0023773417472839355\n",
            "7000it [00:24, 309.02it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-14\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-14\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-14\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-14\n",
            "INFO:__main__:  EVALERR:  0.0019407720565795899\n",
            "7500it [00:26, 290.83it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-15\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-15\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-15\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-15\n",
            "INFO:__main__:  EVALERR:  0.0017817076444625855\n",
            "8000it [00:28, 274.62it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-16\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 0.18887560283756186, 'length_ratio': 0.375, 'translation_length': 3, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-16\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-16\n",
            "INFO:__main__:  EVALERR:  0.0016973322629928588\n",
            "8500it [00:30, 288.40it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 55.5556, 'rouge2': 25.0, 'rougeL': 55.5556, 'rougeLsum': 55.5556}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3, 0.1111111111111111, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.25, 'translation_length': 10, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-17\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-17\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 55.5556, 'rouge2': 25.0, 'rougeL': 55.5556, 'rougeLsum': 55.5556}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.3, 0.1111111111111111, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.25, 'translation_length': 10, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-17\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-17\n",
            "INFO:__main__:  EVALERR:  0.0013607492446899413\n",
            "9000it [00:31, 299.31it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-18\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-18\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-18\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-18\n",
            "INFO:__main__:  EVALERR:  0.0009070963859558105\n",
            "9500it [00:33, 307.71it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-19\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-19\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-19\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-19\n",
            "INFO:__main__:  EVALERR:  0.0006544122695922852\n",
            "10000it [00:34, 314.29it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-20\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-20\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-20\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-20\n",
            "INFO:__main__:  EVALERR:  0.0009602442979812622\n",
            "10500it [00:36, 322.57it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-21\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-21\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-21\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-21\n",
            "INFO:__main__:  EVALERR:  0.0006333649754524231\n",
            "11000it [00:37, 324.65it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-22\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-22\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-22\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-22\n",
            "INFO:__main__:  EVALERR:  0.00034923988580703736\n",
            "11500it [00:39, 314.12it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-23\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-23\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-23\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-23\n",
            "INFO:__main__:  EVALERR:  0.00043957042694091797\n",
            "12000it [00:41, 295.73it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-24\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-24\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-24\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-24\n",
            "INFO:__main__:  EVALERR:  0.0004472744166851044\n",
            "12500it [00:43, 282.00it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-25\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-25\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-25\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-25\n",
            "INFO:__main__:  EVALERR:  0.00034043195843696595\n",
            "13000it [00:45, 296.34it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-26\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-26\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-26\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-26\n",
            "INFO:__main__:  EVALERR:  0.0005287981033325195\n",
            "13500it [00:46, 306.29it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-27\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-27\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-27\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-27\n",
            "INFO:__main__:  EVALERR:  0.0004143125414848328\n",
            "14000it [00:48, 314.48it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-28\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-28\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-28\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-28\n",
            "INFO:__main__:  EVALERR:  0.0002139611691236496\n",
            "14500it [00:49, 317.42it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-29\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-29\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-29\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-29\n",
            "INFO:__main__:  EVALERR:  0.00019358052313327788\n",
            "15000it [00:51, 322.67it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-30\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-30\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-30\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-30\n",
            "INFO:__main__:  EVALERR:  0.00022538171708583833\n",
            "15500it [00:52, 328.09it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-31\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-31\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-31\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-31\n",
            "INFO:__main__:  EVALERR:  0.00023525406420230865\n",
            "16000it [00:54, 317.36it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-32\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-32\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-32\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-32\n",
            "INFO:__main__:  EVALERR:  0.0003575293123722076\n",
            "16500it [00:56, 298.73it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-33\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-33\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-33\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-33\n",
            "INFO:__main__:  EVALERR:  0.00024795173108577726\n",
            "17000it [00:58, 285.83it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-34\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-34\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-34\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-34\n",
            "INFO:__main__:  EVALERR:  0.00029804441332817076\n",
            "17500it [00:59, 300.37it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-35\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-35\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-35\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-35\n",
            "INFO:__main__:  EVALERR:  0.00026837152242660523\n",
            "18000it [01:01, 309.08it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-36\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-36\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-36\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-36\n",
            "INFO:__main__:  EVALERR:  0.00022293971478939056\n",
            "18500it [01:02, 315.92it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-37\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-37\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-37\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-37\n",
            "INFO:__main__:  EVALERR:  0.00014915551245212554\n",
            "19000it [01:03, 322.01it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-38\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-38\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-38\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-38\n",
            "INFO:__main__:  EVALERR:  0.00012690576910972596\n",
            "19500it [01:05, 327.76it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-39\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-39\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-39\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-39\n",
            "INFO:__main__:  EVALERR:  0.0004631466269493103\n",
            "20000it [01:06, 330.66it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-40\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-40\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-40\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-40\n",
            "INFO:__main__:  EVALERR:  0.0001568232625722885\n",
            "20500it [01:08, 317.91it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-41\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-41\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-41\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-41\n",
            "INFO:__main__:  EVALERR:  0.00015863308310508728\n",
            "21000it [01:10, 296.59it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-42\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-42\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-42\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-42\n",
            "INFO:__main__:  EVALERR:  9.676785767078399e-05\n",
            "21500it [01:12, 281.89it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-43\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-43\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-43\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-43\n",
            "INFO:__main__:  EVALERR:  0.0001567033529281616\n",
            "22000it [01:14, 295.75it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-44\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-44\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-44\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-44\n",
            "INFO:__main__:  EVALERR:  8.247362077236176e-05\n",
            "22500it [01:15, 307.16it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-45\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-45\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-45\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-45\n",
            "INFO:__main__:  EVALERR:  0.0001701779067516327\n",
            "23000it [01:17, 312.60it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-46\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-46\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-46\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-46\n",
            "INFO:__main__:  EVALERR:  0.0002327028512954712\n",
            "23500it [01:18, 320.02it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-47\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-47\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-47\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-47\n",
            "INFO:__main__:  EVALERR:  7.31913223862648e-05\n",
            "24000it [01:20, 325.00it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-48\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-48\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-48\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-48\n",
            "INFO:__main__:  EVALERR:  0.00013099373877048493\n",
            "24500it [01:21, 327.83it/s]Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-49\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-49\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-49\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-49\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/valid-step-50\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/valid-step-50\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}\n",
            "INFO:__main__:{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 8, 'reference_length': 8}\n",
            "./finetuneoutput/test-step-50\n",
            "INFO:__main__:Saving model outputs to ./finetuneoutput/test-step-50\n",
            "24500it [01:24, 288.77it/s]\n"
          ]
        }
      ],
      "source": [
        "!python ${TRAIN_SCRIPT_PATH} --model_name_or_path ${MODEL_PATH} \\\n",
        "\t--test_file ${INPUT_DIR} \\\n",
        "\t--validation_file ${INPUT_DIR} \\\n",
        "\t--train_file ${INPUT_DIR} \\\n",
        "\t--output_dir ${OUTPUT_DIR} \\\n",
        "\t--per_device_train_batch_size=16 \\\n",
        "\t--per_device_eval_batch_size=16 \\\n",
        "\t--max_target_length 512 \\\n",
        "\t--max_length 512 \\\n",
        "\t--num_train_epochs 50 \\\n",
        "\t--save_steps 10000 \\\n",
        "\t--num_beams 5 \\\n",
        "  --preprocessing_num_workers 24 \\\n",
        "  --exp_name ${EXP_NAME}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE1Kd-7hK3Ci"
      },
      "outputs": [],
      "source": [
        "# !pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "c6rNHwKXXAh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecdd3584-713f-4ca0-ff36-5f622bbb00f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-14 14:39:31.424671: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-14 14:39:32.411762: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-14 14:39:32.411894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-14 14:39:32.411914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "WARNING:datasets.builder:Using custom data configuration default-57bed1cb1d8906fd\n",
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/json/default-57bed1cb1d8906fd/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n",
            "100% 3/3 [00:00<00:00, 850.48it/s]\n",
            "loading configuration file /content/GODEL/GODEL/GODEL-Base/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/GODEL/GODEL/GODEL-Base\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 3072,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32102\n",
            "}\n",
            "\n",
            "loading file spiece.model\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading weights file /content/GODEL/GODEL/GODEL-Base/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/GODEL/GODEL/GODEL-Base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Generation config file not found, using a generation config created from the model config.\n",
            "Assigning [PAD] to the pad_token key of the tokenizer\n",
            "WARNING:datasets.arrow_dataset:num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n",
            "Processing dataset:   0% 0/1 [00:00<?, ?ba/s]<class 'datasets.formatting.formatting.LazyBatch'>\n",
            "-------------------------------\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Processing dataset: 100% 1/1 [00:00<00:00, 75.17ba/s]\n",
            "WARNING:datasets.arrow_dataset:num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n",
            "Processing dataset:   0% 0/1 [00:00<?, ?ba/s]<class 'datasets.formatting.formatting.LazyBatch'>\n",
            "-------------------------------\n",
            "Processing dataset: 100% 1/1 [00:00<00:00, 389.99ba/s]\n",
            "WARNING:datasets.arrow_dataset:num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n",
            "Processing dataset:   0% 0/1 [00:00<?, ?ba/s]<class 'datasets.formatting.formatting.LazyBatch'>\n",
            "-------------------------------\n",
            "Processing dataset: 100% 1/1 [00:00<00:00, 414.46ba/s]\n",
            "INFO:__main__:Sample 0 of the training set: {'input_ids': [863, 5607, 140, 13, 3874, 12, 1022, 7, 2452, 44, 204, 6218, 5, 32101, 9561, 834, 27608, 834, 4350, 19, 1022, 7, 2452, 6, 9561, 834, 715, 19, 204, 6218, 3, 15425, 1, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100, 32100], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [10625, 6, 356, 8, 9561, 10, 580, 12, 446, 6119, 44, 204, 6218, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/content/GODEL/GODEL/generate.py:480: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"./utils/rouge_metric.py\")\n",
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 23.5294, 'rouge2': 0.0, 'rougeL': 23.5294, 'rougeLsum': 23.5294}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.2222222222222222, 0.0, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.125, 'translation_length': 9, 'reference_length': 8}\n",
            "/content/GODEL/prediction/valid-results.json\n",
            "INFO:__main__:Saving model outputs to /content/GODEL/prediction/valid-results.json\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "INFO:__main__:{'rouge1': 23.5294, 'rouge2': 0.0, 'rougeL': 23.5294, 'rougeLsum': 23.5294}\n",
            "INFO:__main__:{'bleu': 0.0, 'precisions': [0.2222222222222222, 0.0, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.125, 'translation_length': 9, 'reference_length': 8}\n",
            "/content/GODEL/prediction/test-results.json\n",
            "INFO:__main__:Saving model outputs to /content/GODEL/prediction/test-results.json\n"
          ]
        }
      ],
      "source": [
        "!python /content/GODEL/GODEL/generate.py --model_name_or_path /content/GODEL/GODEL/GODEL-Base \\\n",
        "                                         --validation_file /content/GODEL/GODEL/data/data.json \\\n",
        "                                         --train_file /content/GODEL/GODEL/data/data.json \\\n",
        "                                         --output_dir /content/GODEL/prediction \\\n",
        "                                         --per_device_eval_batch_size=16 \\\n",
        "                                         --max_target_length 128 \\\n",
        "                                         --max_length 512  \\\n",
        "                                         --preprocessing_num_workers 24 \\\n",
        "                                         --num_beams 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/file.zip /content/GODEL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "827-nEZ7byZP",
        "outputId": "8094e38d-7e9d-449d-f42a-259fc391d884"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/GODEL/ (stored 0%)\n",
            "  adding: content/GODEL/.git/ (stored 0%)\n",
            "  adding: content/GODEL/.git/packed-refs (deflated 30%)\n",
            "  adding: content/GODEL/.git/index (deflated 53%)\n",
            "  adding: content/GODEL/.git/config (deflated 32%)\n",
            "  adding: content/GODEL/.git/HEAD (stored 0%)\n",
            "  adding: content/GODEL/.git/info/ (stored 0%)\n",
            "  adding: content/GODEL/.git/info/exclude (deflated 28%)\n",
            "  adding: content/GODEL/.git/hooks/ (stored 0%)\n",
            "  adding: content/GODEL/.git/hooks/pre-merge-commit.sample (deflated 39%)\n",
            "  adding: content/GODEL/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: content/GODEL/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: content/GODEL/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: content/GODEL/.git/hooks/fsmonitor-watchman.sample (deflated 52%)\n",
            "  adding: content/GODEL/.git/hooks/pre-commit.sample (deflated 45%)\n",
            "  adding: content/GODEL/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: content/GODEL/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: content/GODEL/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: content/GODEL/.git/hooks/pre-push.sample (deflated 50%)\n",
            "  adding: content/GODEL/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: content/GODEL/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: content/GODEL/.git/objects/ (stored 0%)\n",
            "  adding: content/GODEL/.git/objects/info/ (stored 0%)\n",
            "  adding: content/GODEL/.git/objects/pack/ (stored 0%)\n",
            "  adding: content/GODEL/.git/objects/pack/pack-1c4724829385d4bf915b75431d5059a3c7e23349.pack (deflated 0%)\n",
            "  adding: content/GODEL/.git/objects/pack/pack-1c4724829385d4bf915b75431d5059a3c7e23349.idx (deflated 9%)\n",
            "  adding: content/GODEL/.git/description (deflated 14%)\n",
            "  adding: content/GODEL/.git/logs/ (stored 0%)\n",
            "  adding: content/GODEL/.git/logs/HEAD (deflated 26%)\n",
            "  adding: content/GODEL/.git/logs/refs/ (stored 0%)\n",
            "  adding: content/GODEL/.git/logs/refs/heads/ (stored 0%)\n",
            "  adding: content/GODEL/.git/logs/refs/heads/main (deflated 26%)\n",
            "  adding: content/GODEL/.git/logs/refs/remotes/ (stored 0%)\n",
            "  adding: content/GODEL/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/GODEL/.git/logs/refs/remotes/origin/HEAD (deflated 26%)\n",
            "  adding: content/GODEL/.git/refs/ (stored 0%)\n",
            "  adding: content/GODEL/.git/refs/heads/ (stored 0%)\n",
            "  adding: content/GODEL/.git/refs/heads/main (stored 0%)\n",
            "  adding: content/GODEL/.git/refs/tags/ (stored 0%)\n",
            "  adding: content/GODEL/.git/refs/remotes/ (stored 0%)\n",
            "  adding: content/GODEL/.git/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/GODEL/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: content/GODEL/.git/branches/ (stored 0%)\n",
            "  adding: content/GODEL/data/ (stored 0%)\n",
            "  adding: content/GODEL/data/data/ (stored 0%)\n",
            "  adding: content/GODEL/data/data/.create (stored 0%)\n",
            "  adding: content/GODEL/data/grounded/ (stored 0%)\n",
            "  adding: content/GODEL/data/grounded/src/ (stored 0%)\n",
            "  adding: content/GODEL/data/grounded/src/commoncrawl.py (deflated 67%)\n",
            "  adding: content/GODEL/data/grounded/src/Makefile.official (deflated 63%)\n",
            "  adding: content/GODEL/data/grounded/src/Makefile.official.targets (deflated 89%)\n",
            "  adding: content/GODEL/data/grounded/src/create_official_data.py (deflated 72%)\n",
            "  adding: content/GODEL/data/grounded/src/ids2refs.py (deflated 48%)\n",
            "  adding: content/GODEL/data/grounded/Makefile (deflated 78%)\n",
            "  adding: content/GODEL/data/grounded/README.md (deflated 59%)\n",
            "  adding: content/GODEL/data/grounded/lists/ (stored 0%)\n",
            "  adding: content/GODEL/data/grounded/lists/subreddits-official.txt (deflated 44%)\n",
            "  adding: content/GODEL/data/grounded/lists/valid.hashes (deflated 42%)\n",
            "  adding: content/GODEL/data/grounded/lists/test-multiref.sets (deflated 47%)\n",
            "  adding: content/GODEL/data/grounded/lists/domains-official.txt (deflated 58%)\n",
            "  adding: content/GODEL/data/grounded/lists/test-multiref.hashes (deflated 44%)\n",
            "  adding: content/GODEL/data/grounded/lists/test.hashes (deflated 42%)\n",
            "  adding: content/GODEL/data/grounded/lists/cc-match.tsv (deflated 75%)\n",
            "  adding: content/GODEL/data/ungrounded/ (stored 0%)\n",
            "  adding: content/GODEL/data/ungrounded/data/ (stored 0%)\n",
            "  adding: content/GODEL/data/ungrounded/data/test-multi-refs-ids.txt (deflated 82%)\n",
            "  adding: content/GODEL/data/ungrounded/data/keys-small.tar (deflated 1%)\n",
            "  adding: content/GODEL/data/ungrounded/data/keys-test.gz (deflated 9%)\n",
            "  adding: content/GODEL/data/ungrounded/configs/ (stored 0%)\n",
            "  adding: content/GODEL/data/ungrounded/configs/Makefile.local (deflated 46%)\n",
            "  adding: content/GODEL/data/ungrounded/configs/Makefile.targets.small (deflated 84%)\n",
            "  adding: content/GODEL/data/ungrounded/configs/Makefile.targets.full (deflated 88%)\n",
            "  adding: content/GODEL/data/ungrounded/configs/Makefile.common (deflated 90%)\n",
            "  adding: content/GODEL/data/ungrounded/src/ (stored 0%)\n",
            "  adding: content/GODEL/data/ungrounded/src/create-multiref.py (deflated 58%)\n",
            "  adding: content/GODEL/data/ungrounded/src/reddit.py (deflated 70%)\n",
            "  adding: content/GODEL/data/ungrounded/Makefile (deflated 66%)\n",
            "  adding: content/GODEL/data/ungrounded/README.md (deflated 45%)\n",
            "  adding: content/GODEL/data/ungrounded/lists/ (stored 0%)\n",
            "  adding: content/GODEL/data/ungrounded/lists/words.blocklist.txt (deflated 7%)\n",
            "  adding: content/GODEL/data/ungrounded/lists/subreddits.blocklist.txt (deflated 10%)\n",
            "  adding: content/GODEL/data/dummy_data/ (stored 0%)\n",
            "  adding: content/GODEL/data/dummy_data/dstc7/ (stored 0%)\n",
            "  adding: content/GODEL/data/dummy_data/dstc7/dstc7_h100.tsv (deflated 56%)\n",
            "  adding: content/GODEL/data/dummy_data/msmarco/ (stored 0%)\n",
            "  adding: content/GODEL/data/dummy_data/msmarco/train_v2.1.json (deflated 70%)\n",
            "  adding: content/GODEL/data/dummy_data/unifedqa/ (stored 0%)\n",
            "  adding: content/GODEL/data/dummy_data/unifedqa/dataset2/ (stored 0%)\n",
            "  adding: content/GODEL/data/dummy_data/unifedqa/dataset2/train_h10.tsv (deflated 79%)\n",
            "  adding: content/GODEL/data/dummy_data/unifedqa/dataset1/ (stored 0%)\n",
            "  adding: content/GODEL/data/dummy_data/unifedqa/dataset1/train_h10.tsv (deflated 92%)\n",
            "  adding: content/GODEL/data/dummy_data/reddit/ (stored 0%)\n",
            "  adding: content/GODEL/data/dummy_data/reddit/dialogpt.t1000.txt (deflated 59%)\n",
            "  adding: content/GODEL/data/README.md (deflated 35%)\n",
            "  adding: content/GODEL/requirements.txt (deflated 37%)\n",
            "  adding: content/GODEL/scripts/ (stored 0%)\n",
            "  adding: content/GODEL/scripts/grounded_converter.py (deflated 76%)\n",
            "  adding: content/GODEL/scripts/create_downstream_dataset.sh (deflated 59%)\n",
            "  adding: content/GODEL/scripts/create_reddit.py (deflated 64%)\n",
            "  adding: content/GODEL/scripts/downstream_tasks_converter.py (deflated 79%)\n",
            "  adding: content/GODEL/scripts/create_reddit_dataset.sh (deflated 45%)\n",
            "  adding: content/GODEL/scripts/create_grounded_dataset.sh (deflated 58%)\n",
            "  adding: content/GODEL/doc/ (stored 0%)\n",
            "  adding: content/GODEL/doc/reminderbot.png (deflated 12%)\n",
            "  adding: content/GODEL/doc/interaction_interface_example.png (deflated 27%)\n",
            "  adding: content/GODEL/doc/GODEL.png (deflated 7%)\n",
            "  adding: content/GODEL/SUPPORT.md (deflated 47%)\n",
            "  adding: content/GODEL/prediction/ (stored 0%)\n",
            "  adding: content/GODEL/prediction/test-results.json (deflated 50%)\n",
            "  adding: content/GODEL/prediction/valid-results.json (deflated 50%)\n",
            "  adding: content/GODEL/.github/ (stored 0%)\n",
            "  adding: content/GODEL/.github/workflows/ (stored 0%)\n",
            "  adding: content/GODEL/.github/workflows/codeql-analysis.yml (deflated 53%)\n",
            "  adding: content/GODEL/SECURITY.md (deflated 53%)\n",
            "  adding: content/GODEL/.gitignore (deflated 46%)\n",
            "  adding: content/GODEL/README.md (deflated 64%)\n",
            "  adding: content/GODEL/CODE_OF_CONDUCT.md (deflated 61%)\n",
            "  adding: content/GODEL/GODEL/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/index (deflated 72%)\n",
            "  adding: content/GODEL/GODEL/.git/COMMIT_EDITMSG (deflated 86%)\n",
            "  adding: content/GODEL/GODEL/.git/config (deflated 28%)\n",
            "  adding: content/GODEL/GODEL/.git/HEAD (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/info/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/info/exclude (deflated 28%)\n",
            "  adding: content/GODEL/GODEL/.git/hooks/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/hooks/pre-merge-commit.sample (deflated 39%)\n",
            "  adding: content/GODEL/GODEL/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: content/GODEL/GODEL/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: content/GODEL/GODEL/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: content/GODEL/GODEL/.git/hooks/fsmonitor-watchman.sample (deflated 52%)\n",
            "  adding: content/GODEL/GODEL/.git/hooks/pre-commit.sample (deflated 45%)\n",
            "  adding: content/GODEL/GODEL/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: content/GODEL/GODEL/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: content/GODEL/GODEL/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: content/GODEL/GODEL/.git/hooks/pre-push.sample (deflated 50%)\n",
            "  adding: content/GODEL/GODEL/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: content/GODEL/GODEL/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/d3/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/d3/bf7b60e4f5b42d3de3861f773a873a77c3331a (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/df/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/df/36fcfb72584e00488330b560ebcf34a41c64c2 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/f7/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/f7/0075df092c1fb424abf01e3306fa359ad96d96 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/41/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/41/235286563508e0feb4c451a34b598ef822ec21 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/f4/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/f4/6224858a6d29f9cfd6f089d0301f60dbf6e378 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/9a/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/9a/fce66aec0db71f50e58bb2f747076436a650cb (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/54/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/54/a4795de27d4f6822e997dd225fa465b3dd9754 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/3d/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/3d/259536231fa33cc9e53fc2306c9c091d2892ca (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/de/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/de/a2d1ea485d825b734d1fedee3d3a55f5e724a7 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/15/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/15/be1da62daec30acd4ea15ee60b0b0645b7a2b7 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/b0/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/b0/4421581c258bc5a5d8f29fee2a10514e7473f1 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/info/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/95/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/95/ea3a7a4181863caae4b3a73f2a8e156a8484c1 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/fc/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/fc/cd9355e331420967612cafc29f69e2dcebfc79 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/fc/4c9a6b38041ff1e6062349643f628f292a7cd7 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/bb/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/bb/25d923eb4a3b5b97cdcc9d5be5895fdea65fe9 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/b4/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/b4/1ed2cfd81a699dc25a9f60139568ddfbece70c (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/0d/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/0d/da4de3f0ae38052e58d25e7adda10822c4536e (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/0d/436015c3dc09a23ff47aefc3107296f55943dc (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/e9/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/e9/558405fdcc02f12d757acb308e02937a7444f1 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/e8/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/e8/ae66decd45021cd35654f71c8edbbb8b4a4ca9 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/6d/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/6d/67005fde82c661006196e234fed9c1b76fb68a (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/9f/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/9f/cc20054d4697509bc931fcfa56bcca1c1ebb26 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/81/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/81/d07a5c3e6a4582353579223699974ddb7101f5 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/f3/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/f3/d2503fc2a44b5053b0837ebea6e87a2d339a43 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/f3/87c75a3c915ddb4dc916937c06e3b6f7e3ae24 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/27/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/27/e6266611cdb09740634259b9ecd70ff63364e2 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/32/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/32/75757048661ec5a83a415e6fee82cc30a5c648 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/1c/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/1c/ee40c78fc9116f65d0b01cea49c99a6468f07b (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/b8/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/b8/cd6f4165370cc1f60717bf72be5d836bca2302 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/0a/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/0a/37613b6ece395a28e45c431c5e61369397b607 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/da/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/da/545314e26cf26c6dd3b0b12b746a40204270e5 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/29/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/29/551548a0f290a22ac69587d74c316364677ced (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/2d/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/2d/800c8e534003f18195f7703f4bde2f944b9fd6 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/2d/aa28d0033fea9f5ba491cac742247d2e8f771b (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/51/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/51/defd768cd599e1fdb9bf3fb9268eabd36a8b75 (deflated 10%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/51/cd78126be359c622ee9ae0e874c4b6837910a1 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/d2/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/d2/92753630aefba6a2893bf69abfa391e1627b01 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/d2/d72703a62d28f05ce887ab75e13bc578ee884b (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/d1/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/d1/f49e75e02ad6773add10a6575dc85f40fb4f90 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/e2/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/e2/90f577220795bf94da63e5c2215d882b81cca8 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/11/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/11/1aaefd42197e60d65071378c3e554d24c3aa60 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/f2/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/f2/2d8fd99b1659f6e453921b30dcc1031ff59488 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/a2/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/a2/7b7195d6f0434a2d9f19ff45eb9ae193d71c3c (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/a2/219c1dd8cd2757a24b4ebae583119eceaf271d (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/04/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/04/086493405dc4435d2d6faa0bba8eccac32c20c (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/96/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/96/5e42da0ece4c14444c48d21accc7671cdd6631 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/2a/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/2a/8041b7a0645572412beb3614b64b349a9cab9e (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/2a/0db95ab0ee0edd85b45e1a7971ac39c0d7d073 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/8b/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/8b/205ecaa35a895418085dcbf70337b567ec22f8 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/49/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/49/e53cdc3cc0ab86dc06849ab3f439e629668c3a (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/7b/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/7b/796b5fb2f019a74a55e759bcb6bc6f78f3bb08 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/25/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/25/535296a4e97373aac00af11dfed55b1655c76d (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/4b/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/4b/3029d973aa4bafc019827160994821d5a2cff1 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/5a/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/5a/24ae4c18b2565f7c02e71547b655aaedf46683 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/5a/cfd55fdc8f2fb69d35f874cc8daaf50d2e9fe2 (deflated 3%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/cc/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/cc/64c8894ca30af9cfbbc54ad9fba1ade0cd53e1 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/b1/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/b1/b521d742243da7915cfa12caed34d3cc662587 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/63/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/63/eb05f711c8cb5cda45128882fa69c351f105fb (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/8e/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/8e/e5fcf68f2f69c6ffc79bf6e1baee32fa6280f9 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/9c/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/9c/fcdd360dfa1fe909f0f5fcad859459f02728ef (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/pack/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/pack/pack-0e18167dd440b15899c73570171d322769a6ab6f.pack (deflated 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/pack/pack-0e18167dd440b15899c73570171d322769a6ab6f.idx (deflated 89%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/3f/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/3f/8922b337e13ad2f7c8ef5d9884ae9f3a1afad0 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/77/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/77/f27b82e85b1fb6c501eece552c168b8a7cf851 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/e6/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/9d/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/9d/4dc83eedb429a11e2a6ef456c98b3dd0726642 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/ae/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/ae/7dab79467227b2c0e05faefca705585fb9af29 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/fd/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/fd/af6a1cb2a2373e8be2583a111bba5add70636b (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/e0/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/e0/d1daf149e03c0425960e3884b5f3c563a5fccb (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/36/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/36/ac9ece499f2f448cc2f1035a9da8c719be726c (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/59/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/59/cf0a152f75ba259376588371fd494f555ed915 (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/5f/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/objects/5f/afe3c2bc58a08a421eae3610bd500c5749b51f (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/description (deflated 14%)\n",
            "  adding: content/GODEL/GODEL/.git/.COMMIT_EDITMSG.swp (deflated 90%)\n",
            "  adding: content/GODEL/GODEL/.git/refs/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/refs/heads/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/refs/tags/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.git/branches/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/data/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/data/data.json (deflated 30%)\n",
            "  adding: content/GODEL/GODEL/html/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/html/package.json (deflated 59%)\n",
            "  adding: content/GODEL/GODEL/html/public/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/html/public/favicon.ico (deflated 80%)\n",
            "  adding: content/GODEL/GODEL/html/public/index.html (deflated 41%)\n",
            "  adding: content/GODEL/GODEL/html/src/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/html/src/main.js (deflated 15%)\n",
            "  adding: content/GODEL/GODEL/html/src/components/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/html/src/components/chat.vue (deflated 61%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/main.scss (deflated 62%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/partials/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/partials/_header.scss (deflated 33%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/partials/_picker.scss (stored 0%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/partials/_base.scss (deflated 42%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/partials/_window.scss (deflated 31%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/partials/_messages.scss (deflated 58%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/partials/_message.scss (deflated 69%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/partials/_input.scss (deflated 71%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/partials/_features.scss (deflated 13%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/modules/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/modules/_typography.scss (deflated 17%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/modules/_variables.scss (deflated 61%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/modules/_all.scss (deflated 40%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/modules/_colors.scss (deflated 29%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/modules/_responsiveness.scss (stored 0%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/modules/_mixins.scss (deflated 50%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/modules/_defaults.scss (deflated 48%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/scss/modules/_animations.scss (deflated 42%)\n",
            "  adding: content/GODEL/GODEL/html/src/assets/logo.png (deflated 5%)\n",
            "  adding: content/GODEL/GODEL/html/src/App.vue (deflated 46%)\n",
            "  adding: content/GODEL/GODEL/html/babel.config.js (deflated 7%)\n",
            "  adding: content/GODEL/GODEL/html/README.md (deflated 41%)\n",
            "  adding: content/GODEL/GODEL/utils/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/utils/__pycache__/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/utils/__pycache__/text_normalization.cpython-38.pyc (deflated 35%)\n",
            "  adding: content/GODEL/GODEL/utils/rouge_metric.py (deflated 62%)\n",
            "  adding: content/GODEL/GODEL/utils/text_normalization.py (deflated 55%)\n",
            "  adding: content/GODEL/GODEL/utils/bleu_metric.py (deflated 59%)\n",
            "  adding: content/GODEL/GODEL/utils/bleu_for_gpt2.py (deflated 59%)\n",
            "  adding: content/GODEL/GODEL/configs/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/configs/G16_config.yaml (deflated 27%)\n",
            "  adding: content/GODEL/GODEL/configs/G4_config.yaml (deflated 27%)\n",
            "  adding: content/GODEL/GODEL/configs/G8_config.yaml (deflated 27%)\n",
            "  adding: content/GODEL/GODEL/server.py (deflated 57%)\n",
            "  adding: content/GODEL/GODEL/GODEL-Base/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/GODEL-Base/config.json (deflated 60%)\n",
            "  adding: content/GODEL/GODEL/GODEL-Base/tokenizer_config.json (deflated 78%)\n",
            "  adding: content/GODEL/GODEL/GODEL-Base/tokenizer.json (deflated 59%)\n",
            "  adding: content/GODEL/GODEL/GODEL-Base/training_args.bin (deflated 49%)\n",
            "  adding: content/GODEL/GODEL/GODEL-Base/special_tokens_map.json (deflated 83%)\n",
            "  adding: content/GODEL/GODEL/GODEL-Base/pytorch_model.bin (deflated 8%)\n",
            "  adding: content/GODEL/GODEL/.lock (stored 0%)\n",
            "  adding: content/GODEL/GODEL/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/__init__.py (deflated 8%)\n",
            "  adding: content/GODEL/GODEL/train.py (deflated 74%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-43 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-30 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-47 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-6 (deflated 44%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-33 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-30 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-37 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-20 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-10 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-35 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-21 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-38 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-28 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-37 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-50 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-3 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-47 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-25 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-36 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-46 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-2 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-24 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-22 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-42 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-34 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-22 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-26 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-9 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-45 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-49 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-13 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-43 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-32 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-16 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-21 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-32 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-2 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-39 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-33 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-50 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-29 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-36 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-28 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-19 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-5 (deflated 44%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-19 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-15 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-34 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-17 (deflated 44%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-18 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-11 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-31 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-40 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-8 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-8 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-27 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-11 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-41 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-15 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-9 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-3 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-6 (deflated 44%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-38 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-5 (deflated 44%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-44 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-17 (deflated 44%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-1 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-45 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-27 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-23 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-39 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-41 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-46 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-12 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-7 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-14 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-48 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-23 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-13 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-40 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-31 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-4 (deflated 44%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-42 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-49 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-25 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-7 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-4 (deflated 44%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-20 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-44 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-1 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-14 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-12 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-29 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-24 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-35 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-26 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-18 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-16 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/valid-step-10 (deflated 24%)\n",
            "  adding: content/GODEL/GODEL/finetuneoutput/test-step-48 (deflated 43%)\n",
            "  adding: content/GODEL/GODEL/generate.py (deflated 73%)\n",
            "  adding: content/GODEL/GODEL/datasets_loader/ (stored 0%)\n",
            "  adding: content/GODEL/GODEL/datasets_loader/wow_dataset.py (deflated 59%)\n",
            "  adding: content/GODEL/GODEL/datasets_loader/woi_dataset.py (deflated 59%)\n",
            "  adding: content/GODEL/GODEL/datasets_loader/grounded_dataset.py (deflated 60%)\n",
            "  adding: content/GODEL/GODEL/datasets_loader/reddit_dataset.py (deflated 60%)\n",
            "  adding: content/GODEL/GODEL/datasets_loader/multiwoz_dataset.py (deflated 59%)\n",
            "  adding: content/GODEL/GODEL/datasets_loader/coqa_dataset.py (deflated 59%)\n",
            "  adding: content/GODEL/examples/ (stored 0%)\n",
            "  adding: content/GODEL/examples/dstc9/ (stored 0%)\n",
            "  adding: content/GODEL/examples/dstc9/create_data.sh (deflated 55%)\n",
            "  adding: content/GODEL/examples/dstc9/dstc9_server.py (deflated 51%)\n",
            "  adding: content/GODEL/examples/dstc9/dstc9_dataset.py (deflated 64%)\n",
            "  adding: content/GODEL/examples/dstc9/converter.py (deflated 63%)\n",
            "  adding: content/GODEL/LICENSE (deflated 44%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mLhT-2ELcT8w",
        "outputId": "fa1679d9-e2aa-4c06-f2d7-251411fcd9a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a7f78bb7-aea2-4770-9c17-9e26ca35cfd9\", \"file.zip\", 2586831010)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOi0Nq2KUTHXO1kYG6tblAv",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}